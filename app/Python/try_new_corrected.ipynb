{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: dlib in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (19.24.4)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install dlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from opencv-python) (2.0.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: matplotlib in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.9.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.23 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (2.0.0)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (10.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\lenovo\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\lenovo\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: face_recognition in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.3.0)\n",
            "Requirement already satisfied: face-recognition-models>=0.3.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from face_recognition) (0.3.0)\n",
            "Requirement already satisfied: Click>=6.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from face_recognition) (8.1.7)\n",
            "Requirement already satisfied: dlib>=19.7 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from face_recognition) (19.24.4)\n",
            "Requirement already satisfied: numpy in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from face_recognition) (2.0.0)\n",
            "Requirement already satisfied: Pillow in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from face_recognition) (10.3.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\lenovo\\appdata\\roaming\\python\\python311\\site-packages (from Click>=6.0->face_recognition) (0.4.6)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install face_recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import face_recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "def detectCascade(gray, frame):\n",
        "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
        "    for (x, y, w, h) in faces:\n",
        "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
        "        roi_gray = gray[y:y+h, x:x+w]\n",
        "        roi_color = frame[y:y+h, x:x+w]\n",
        "        eyes = eye_cascade.detectMultiScale(roi_gray, 1.1, 3)\n",
        "        for (ex, ey, ew, eh) in eyes:\n",
        "            cv2.rectangle(roi_color, (ex, ey), (ex+ew, ey+eh), (0, 255, 0), 2)\n",
        "    return frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the cascades\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize video capture\n",
        "video_capture = cv2.VideoCapture(0)\n",
        "\n",
        "if not video_capture.isOpened():\n",
        "    print(\"Error: Could not open video capture\")\n",
        "    exit()\n",
        "\n",
        "frame_count = 0\n",
        "\n",
        "while True:\n",
        "    ret, frame = video_capture.read()\n",
        "    if not ret:\n",
        "        print(\"Failed to grab frame\")\n",
        "        break\n",
        "\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    canvas = detectCascade(gray, frame)\n",
        "    \n",
        "    # Save the frame to a file\n",
        "    cv2.imwrite(f'frame_{frame_count}.png', canvas)\n",
        "    frame_count += 1\n",
        "\n",
        "    # Hentikan loop jika ditekan tombol 'q'\n",
        "    if frame_count >= 10:\n",
        "        break\n",
        "\n",
        "video_capture.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "from PIL import Image, ImageDraw\n",
        "def drawImgLandmarks(frame, face_landmarks_list):\n",
        "    pil_image = Image.fromarray(frame)\n",
        "    d = ImageDraw.Draw(pil_image)\n",
        "    index=0\n",
        "    while index < len(face_landmarks_list):\n",
        "        for face_landmarks in face_landmarks_list:\n",
        "            d.line(face_landmarks['chin'],fill=(255,255,255))\n",
        "            d.line(face_landmarks['left_eyebrow'],fill=(255,255,255))\n",
        "            d.line(face_landmarks['right_eyebrow'],fill=(255,255,255))\n",
        "            d.line(face_landmarks['nose_bridge'],fill=(255,255,255))\n",
        "            d.line(face_landmarks['nose_tip'],fill=(255,255,255))\n",
        "            d.line(face_landmarks['left_eye'],fill=(255,255,255))\n",
        "            d.line(face_landmarks['right_eye'],fill=(255,255,255))\n",
        "            d.line(face_landmarks['top_lip'],fill=(255,255,255))\n",
        "            d.line(face_landmarks['bottom_lip'],fill=(255,255,255))\n",
        "        index +=1\n",
        "    rgb_image = pil_image.convert('RGB')\n",
        "    rgb_open_cv_image = np.array(pil_image)\n",
        "    bgr_open_cv_image = cv2.cvtColor(rgb_open_cv_image, cv2.COLOR_RGB2BGR)\n",
        "    return bgr_open_cv_image[:, :, ::-1].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Unsupported image type, must be 8bit gray or RGB image.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[39], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to grab frame\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m face_landmarks_list \u001b[38;5;241m=\u001b[39m \u001b[43mface_recognition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mface_landmarks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_frame\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m current_frame \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(current_frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)  \u001b[38;5;66;03m# Convert to RGB for Matplotlib\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Draw landmarks on the current frame\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\face_recognition\\api.py:177\u001b[0m, in \u001b[0;36mface_landmarks\u001b[1;34m(face_image, face_locations, model)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mface_landmarks\u001b[39m(face_image, face_locations\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlarge\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    169\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;124;03m    Given an image, returns a dict of face feature locations (eyes, nose, etc) for each face in the image\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;124;03m    :return: A list of dicts of face feature locations (eyes, nose, etc)\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 177\u001b[0m     landmarks \u001b[38;5;241m=\u001b[39m \u001b[43m_raw_face_landmarks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mface_locations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    178\u001b[0m     landmarks_as_tuples \u001b[38;5;241m=\u001b[39m [[(p\u001b[38;5;241m.\u001b[39mx, p\u001b[38;5;241m.\u001b[39my) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m landmark\u001b[38;5;241m.\u001b[39mparts()] \u001b[38;5;28;01mfor\u001b[39;00m landmark \u001b[38;5;129;01min\u001b[39;00m landmarks]\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;66;03m# For a definition of each point index, see https://cdn-images-1.medium.com/max/1600/1*AbEg31EgkbXSQehuNJBlWg.png\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\face_recognition\\api.py:156\u001b[0m, in \u001b[0;36m_raw_face_landmarks\u001b[1;34m(face_image, face_locations, model)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_raw_face_landmarks\u001b[39m(face_image, face_locations\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlarge\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m face_locations \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 156\u001b[0m         face_locations \u001b[38;5;241m=\u001b[39m \u001b[43m_raw_face_locations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_image\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    158\u001b[0m         face_locations \u001b[38;5;241m=\u001b[39m [_css_to_rect(face_location) \u001b[38;5;28;01mfor\u001b[39;00m face_location \u001b[38;5;129;01min\u001b[39;00m face_locations]\n",
            "File \u001b[1;32mc:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\face_recognition\\api.py:105\u001b[0m, in \u001b[0;36m_raw_face_locations\u001b[1;34m(img, number_of_times_to_upsample, model)\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cnn_face_detector(img, number_of_times_to_upsample)\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mface_detector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_times_to_upsample\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mRuntimeError\u001b[0m: Unsupported image type, must be 8bit gray or RGB image."
          ]
        }
      ],
      "source": [
        "def drawImgLandmarks(image, face_landmarks_list):\n",
        "    for face_landmarks in face_landmarks_list:\n",
        "        for facial_feature in face_landmarks.keys():\n",
        "            cv2.circle(image, face_landmarks[facial_feature], 2, (255, 255, 0), -1)\n",
        "    return image\n",
        "\n",
        "webcam_video_stream = cv2.VideoCapture(0)\n",
        "all_face_locations = []\n",
        "\n",
        "# Loop through every frame in the video\n",
        "while True:\n",
        "    ret, current_frame = webcam_video_stream.read()\n",
        "    if not ret:\n",
        "        print(\"Failed to grab frame\")\n",
        "        break\n",
        "\n",
        "    face_landmarks_list = face_recognition.face_landmarks(current_frame)\n",
        "    current_frame = cv2.cvtColor(current_frame, cv2.COLOR_BGR2RGB)  # Convert to RGB for Matplotlib\n",
        "\n",
        "    # Draw landmarks on the current frame\n",
        "    current_frame_with_landmarks = drawImgLandmarks(current_frame, face_landmarks_list)\n",
        "\n",
        "    # Display the current frame with landmarks using Matplotlib\n",
        "    plt.imshow(current_frame_with_landmarks)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "webcam_video_stream.release()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "from keras.models import model_from_json\n",
        "webcam_video_stream = cv2.VideoCapture(0)\n",
        "# face_exp_model = model_from_json(open(\"dataset/model/facial_expression_model_structure.json\",\"r\").read())\n",
        "face_exp_model.load_weights('app/python/keras_model.h5')\n",
        "emotions_label = ('marah', 'muak', 'takut', 'gembira', 'sedih', 'surprise','netral')\n",
        "all_face_locations = []\n",
        "while True:\n",
        "    ret,current_frame = webcam_video_stream.read()\n",
        "    current_frame_small = cv2.resize(current_frame,(0,0),fx=0.25,fy=0.25)\n",
        "    all_face_locations = face_recognition.face_locations(current_frame_small,number_of_times_to_upsample=2,model='hog')\n",
        "    for index,current_face_location in enumerate(all_face_locations):\n",
        "#membagi tupel untuk mendapatkan empat nilai posisi wajah\n",
        "        top_pos,right_pos,bottom_pos,left_pos = current_face_location\n",
        "#cubah besaran posisi agar sesuai dengan ukuran bingkai video\n",
        "        top_pos = top_pos*4\n",
        "        right_pos = right_pos*4\n",
        "        bottom_pos = bottom_pos*4\n",
        "        left_pos = left_pos*4\n",
        "    #simpan gambar face\n",
        "        current_face_image = current_frame[top_pos:bottom_pos,left_pos:right_pos]\n",
        "#buat rectangle (opsional)\n",
        "    cv2.rectangle(current_frame,(left_pos,top_pos),(right_pos,bottom_pos),(0,0,255),2)\n",
        "#preprocess\n",
        "    current_face_image = cv2.cvtColor(current_face_image, cv2.COLOR_BGR2GRAY)\n",
        "    current_face_image = cv2.resize(current_face_image, (48, 48))\n",
        "    img_pixels = image.img_to_array(current_face_image)\n",
        "    img_pixels = np.expand_dims(img_pixels, axis = 0)\n",
        "    img_pixels /= 255\n",
        "#mempredisksi dengan pretraining model\n",
        "    exp_predictions = face_exp_model.predict(img_pixels)\n",
        "# menentukan dengan mencari nilai maksimum dari hasil prediksi\n",
        "    max_index = np.argmax(exp_predictions[0])\n",
        "#ambil label emosi\n",
        "    emotion_label = emotions_label[max_index]\n",
        "    print('Ditemukan face {} bagian top:{},right:{},bottom:{},left:{}dengan emosi:{}'.format(index+1,top_pos,right_pos,bottom_pos,left_pos,emotion_label))\n",
        "#display\n",
        "    font = cv2.FONT_HERSHEY_DUPLEX\n",
        "    cv2.putText(current_frame, emotion_label, (left_pos,bottom_pos), font,0.5, (255,255,255),1)\n",
        "#showing gambar\n",
        "    cv2.imshow(\"Webcam Video\",current_frame)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "webcam_video_stream.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
