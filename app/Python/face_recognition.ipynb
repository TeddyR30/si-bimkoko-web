{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install face_recognition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if face_cascade.empty():\n",
    "    raise IOError(\"Error loading haarcascade_frontalface_default.xml\")\n",
    "if eye_cascade.empty():\n",
    "    raise IOError(\"Error loading haarcascade_eye.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectCascade(gray, frame):\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray, 1.1, 3)\n",
    "        for (ex, ey, ew, eh) in eyes:\n",
    "            cv2.rectangle(roi_color, (ex, ey), (ex+ew, ey+eh), (0, 255, 0), 2)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video_capture = cv2.VideoCapture(0)\n",
    "# if not video_capture.isOpened():\n",
    "#     raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "# while True:\n",
    "#     ret, frame = video_capture.read()\n",
    "#     if not ret:\n",
    "#         break\n",
    "#     gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "#     canvas = detectCascade(gray, frame)\n",
    "#     cv2.imshow('Video', canvas)\n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "# video_capture.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image, ImageDraw\n",
    "# def drawImgLandmarks(frame, face_landmarks_list):\n",
    "#     pil_image = Image.fromarray(frame)\n",
    "#     d = ImageDraw.Draw(pil_image)\n",
    "#     index=0\n",
    "#     while index < len(face_landmarks_list):\n",
    "#         for face_landmarks in face_landmarks_list:\n",
    "#             d.line(face_landmarks['chin'],fill=(255,255,255))\n",
    "#             d.line(face_landmarks['left_eyebrow'],fill=(255,255,255))\n",
    "#             d.line(face_landmarks['right_eyebrow'],fill=(255,255,255))\n",
    "#             d.line(face_landmarks['nose_bridge'],fill=(255,255,255))\n",
    "#             d.line(face_landmarks['nose_tip'],fill=(255,255,255))\n",
    "#             d.line(face_landmarks['left_eye'],fill=(255,255,255))\n",
    "#             d.line(face_landmarks['right_eye'],fill=(255,255,255))\n",
    "#             d.line(face_landmarks['top_lip'],fill=(255,255,255))\n",
    "#             d.line(face_landmarks['bottom_lip'],fill=(255,255,255))\n",
    "#         index +=1\n",
    "#     rgb_image = pil_image.convert('RGB')\n",
    "#     rgb_open_cv_image = np.array(pil_image)\n",
    "#     bgr_open_cv_image = cv2.cvtColor(rgb_open_cv_image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "#     return bgr_open_cv_image[:, :, ::-1].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "webcam_video_stream = cv2.VideoCapture(0)\n",
    "all_face_locations = []\n",
    "#loop through every frame in the video\n",
    "while True:\n",
    "    ret,current_frame = webcam_video_stream.read()\n",
    "    face_landmarks_list = face_recognition.face_landmarks(current_frame)\n",
    "    bgr_open_cv_image = drawImgLandmarks(current_frame, face_landmarks_list)\n",
    "    cv2.imshow(\"Video\",bgr_open_cv_image)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "webcam_video_stream.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "from keras.models import model_from_json\n",
    "\n",
    "webcam_video_stream = cv2.VideoCapture(0)\n",
    "face_exp_model = model_from_json(open(\"dataset/model/facial_expression_model_structure.json\",\"r\").read())\n",
    "face_exp_model.load_weights('dataset/model/facial_expression_model_weights.h5')\n",
    "emotions_label = ('marah', 'takut', 'gembira', 'sedih', 'netral')\n",
    "all_face_locations = []\n",
    "while True:\n",
    "    ret,current_frame = webcam_video_stream.read()\n",
    "    current_frame_small = cv2.resize(current_frame,(0,0),fx=0.25,fy=0.25)\n",
    "    all_face_locations = face_recognition.face_locations(current_frame_small,number_of_times_to_upsample=2,model='hog')\n",
    "    for index,current_face_location in enumerate(all_face_locations):top_pos,right_pos,bottom_pos,left_pos = current_face_location\n",
    "    #cubah besaran posisi agar sesuai dengan ukuran bingkai video\n",
    "    top_pos = top_pos*4\n",
    "    right_pos = right_pos*4\n",
    "    bottom_pos = bottom_pos*4\n",
    "    left_pos = left_pos*4\n",
    "#simpan gambar face\n",
    "    current_face_image = current_frame[top_pos:bottom_pos,left_pos:right_pos]\n",
    "#buat rectangle (opsional)\n",
    "    cv2.rectangle(current_frame,(left_pos,top_pos),(right_pos,bottom_pos),(0,0,255),2)\n",
    "#preprocess\n",
    "    current_face_image = cv2.cvtColor(current_face_image, cv2.COLOR_BGR2GRAY)\n",
    "    current_face_image = cv2.resize(current_face_image, (48, 48))\n",
    "    img_pixels = image.img_to_array(current_face_image)\n",
    "    img_pixels = np.expand_dims(img_pixels, axis = 0)\n",
    "    img_pixels /= 255\n",
    "    #mempredisksi dengan pretraining model\n",
    "    exp_predictions = face_exp_model.predict(img_pixels)\n",
    "    # menentukan dengan mencari nilai maksimum dari hasil prediksi\n",
    "    max_index = np.argmax(exp_predictions[0])\n",
    "    #ambil label emosi\n",
    "    emotion_label = emotions_label[max_index]\n",
    "    print('Ditemukan face {} bagian top:{},right:{},bottom:{},left:{}dengan emosi:{}'.format(index+1,top_pos,right_pos,bottom_pos,left_pos,emotion_label))\n",
    "#display\n",
    "    font = cv2.FONT_HERSHEY_DUPLEX\n",
    "    cv2.putText(current_frame, emotion_label, (left_pos,bottom_pos), font,0.5, (255,255,255),1)\n",
    "#showing gambar\n",
    "    cv2.imshow(\"Webcam Video\",current_frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "webcam_video_stream.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
